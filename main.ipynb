{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36025c09-2da3-4839-8cef-f572d187b7b4",
   "metadata": {},
   "source": [
    "# 1. Brain Source Localization with ConvDip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7420bf1a-efa8-4c24-8ad4-e8ca759fabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357c69a8-2553-4cf8-9f91-a63437d4aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing task: LA\n",
      "(59, 3)\n",
      "result saved in: ./result//sample/Test_result_evoked_LA.mat\n",
      "processing task: LV\n",
      "(59, 3)\n",
      "result saved in: ./result//sample/Test_result_evoked_LV.mat\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The subject underwent four tasks, and corresponding EEG data were collected.\n",
    "task list: ['LA','LV','RA','RV']\n",
    "\"\"\"\n",
    "# you can choose single or multiple task ids from task list ['LA','LV','RA','RV']\n",
    "tasks = ['LA', 'LV'] # or 'LA' or ['LA'], etc.\n",
    "# set your result path\n",
    "result_path = './result/'\n",
    "ConvDip_ESI(tasks, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417f0ce4-63f6-43d7-a5e0-45b0fcde8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load result for task: LA\n",
      "(1984, 241)\n"
     ]
    }
   ],
   "source": [
    "# choose only ONE task from ['LA','LV','RA','RV']\n",
    "task = 'LA' \n",
    "s_pred = load_result(task, result_path)\n",
    "print(s_pred.shape) # s_pred: estimated sources at different timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6838b1-be32-4b25-b9fc-b67bb05ad767",
   "metadata": {},
   "source": [
    "# 2. 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10453c03-395e-4c1f-a004-e1cbd19f9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run brain.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695efb0b-c329-4e8c-8af9-0e06cd227f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\iceki\\mne_data\\MNE-sample-data\\MEG\\sample\\sample_audvis_filt-0-40_raw.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "319 events found on stim channel STI 014\n",
      "Event IDs: [ 1  2  3  4  5 32]\n",
      "Removing projector <Projection | Average EEG reference, active : False, n_channels : 60>\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Setting baseline interval to [-0.19979521315838786, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "Loading data for 72 events and 106 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1711']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "17 bad epochs dropped\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 4.1e-09 (2.2e-16 eps * 305 dim * 6.1e+04  max singular value)\n",
      "    Estimated rank (mag + grad): 302\n",
      "    MEG: rank 302 computed from 305 data channels with 3 projectors\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 305 -> 302\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 2035\n",
      "[done]\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.8e-09 (2.2e-16 eps * 305 dim * 4.2e+04  max singular value)\n",
      "    Estimated rank (mag + grad): 302\n",
      "    MEG: rank 302 computed from 305 data channels with 3 projectors\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 305 -> 302\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 1705\n",
      "[done]\n",
      "Reading forward solution from c:\\Users\\iceki\\OneDrive - stevens.edu\\Desktop\\SSW555-Group22\\data\\meg-fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (1984 sources, 102 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.3e-14 (2.2e-16 eps * 102 dim * 1  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Making LCMV beamformer with rank {'mag': 99}\n",
      "Computing inverse operator with 102 channels.\n",
      "    102 out of 102 channels remain after picking\n",
      "Selected 102 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "Computing rank from covariance with rank={'mag': 99}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 1984 sources\n",
      "Filter computation complete\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.3e-14 (2.2e-16 eps * 102 dim * 1  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Making LCMV beamformer with rank {'mag': 99}\n",
      "Computing inverse operator with 102 channels.\n",
      "    102 out of 102 channels remain after picking\n",
      "Selected 102 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "Computing rank from covariance with rank={'mag': 99}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 1984 sources\n",
      "Filter computation complete\n",
      "<SourceEstimate | 1984 vertices, subject : sample, tmin : 53.27872350890343 (ms), tmax : 153.1763300880974 (ms), tstep : 6.659840438612929 (ms), data shape : (1984, 16), ~264 kB>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not load any valid 3D backend\npyvistaqt: No module named 'qtpy'\nnotebook: No module named 'ipyevents'\n\n install pyvistaqt, using pip or conda:\n'pip install pyvistaqt'\n'conda install -c conda-forge pyvistaqt'\n\n or install ipywidgets, if using a notebook backend\n'pip install ipywidgets'\n'conda install -c conda-forge ipywidgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mhemi: Hemisphere id (ie ‘lh’, ‘rh’, ‘both’, or ‘split’). \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mIn the case of ‘lh’, only left hemisphere is shown in the window. \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mIn the case of ‘split’ hemispheres are displayed side-by-side in different viewing panes.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m hemi\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# choose from ['lh', 'rh', 'split', 'both']\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mbrain3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhemi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20608\\3785389983.py:7\u001b[0m, in \u001b[0;36mbrain3d\u001b[1;34m(s_pred, hemi)\u001b[0m\n\u001b[0;32m      5\u001b[0m data_path \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mdata_path()\n\u001b[0;32m      6\u001b[0m subjects_dir \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjects\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m brain \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_source_estimates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# views= #'lateral', \u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhemi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhemi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#'split', #'both', \u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43msurface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#'inflated'\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# time_viewer=False, \u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_traces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# colorbar=False,\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-165>:12\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mne\\viz\\_3d.py:2405\u001b[0m, in \u001b[0;36mplot_source_estimates\u001b[1;34m(stc, subject, surface, hemi, colormap, time_label, smoothing_steps, transparent, alpha, time_viewer, subjects_dir, figure, views, colorbar, clim, cortex, size, background, foreground, initial_time, time_unit, backend, spacing, title, show_traces, src, volume_options, view_layout, add_data_kwargs, brain_kwargs, verbose)\u001b[0m\n\u001b[0;32m   2403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2404\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2405\u001b[0m         backend \u001b[38;5;241m=\u001b[39m \u001b[43m_get_3d_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2406\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[0;32m   2407\u001b[0m         warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo 3D backend found. Resorting to matplotlib 3d.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mne\\viz\\backends\\renderer.py:185\u001b[0m, in \u001b[0;36m_get_3d_backend\u001b[1;34m()\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load any valid 3D backend\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    189\u001b[0m                 (\n\u001b[0;32m    190\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m install pyvistaqt, using pip or conda:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    191\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pyvistaqt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    192\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge pyvistaqt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m or install ipywidgets, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m                     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif using a notebook backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install ipywidgets\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge ipywidgets\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m                 )\n\u001b[0;32m    198\u001b[0m             )\n\u001b[0;32m    199\u001b[0m         )\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     MNE_3D_BACKEND \u001b[38;5;241m=\u001b[39m _check_3d_backend_name(MNE_3D_BACKEND)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not load any valid 3D backend\npyvistaqt: No module named 'qtpy'\nnotebook: No module named 'ipyevents'\n\n install pyvistaqt, using pip or conda:\n'pip install pyvistaqt'\n'conda install -c conda-forge pyvistaqt'\n\n or install ipywidgets, if using a notebook backend\n'pip install ipywidgets'\n'conda install -c conda-forge ipywidgets'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hemi: Hemisphere id (ie ‘lh’, ‘rh’, ‘both’, or ‘split’). \n",
    "In the case of ‘lh’, only left hemisphere is shown in the window. \n",
    "In the case of ‘rh’, only right hemispheres is shown in the window. \n",
    "In the case of ‘both’, both hemispheres are shown in the same window. \n",
    "In the case of ‘split’ hemispheres are displayed side-by-side in different viewing panes.\n",
    "\"\"\"\n",
    "\n",
    "hemi='split' # choose from ['lh', 'rh', 'split', 'both']\n",
    "brain3d(s_pred, hemi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d04f4c-e3ff-49c7-bb34-fe6105612795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
